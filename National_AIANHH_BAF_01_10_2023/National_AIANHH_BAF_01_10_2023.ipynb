{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef8c152-54c8-4654-973d-b7d8162585a8",
   "metadata": {},
   "source": [
    "# National 2020 AIANHH (American Indian Area / Alaska Native Area / Hawaiian Home Land) Block Assignment File and Tribal Block Group Indicator for 2020 Blocks\n",
    "\n",
    "## Background:\n",
    "- We received a request for a national dataset identifying blocks that are in Tribal Block Groups and in AIANHH areas.\n",
    "## Approach:\n",
    "- Read in block-level PL data and query out necessary fields.\n",
    "- Retrieve AIANHH name data using fields in PL file and AIANHH shapefiles.\n",
    "- Retrieve county name data using fields in PL file and county shapefiles.\n",
    "- Assign blocks as in or not Tribal Block Groups and AIANHH based on non-null values.\n",
    "- Concat state datasets to national dataset and clean before exporting.\n",
    "\n",
    "## Sources\n",
    "- Block Level PL data for each state (ex. [Washington block PL 94-171 2020](https://redistrictingdatahub.org/dataset/washington-block-pl-94171-2020/))\n",
    "- AIANHH shapefile for each state (where applicable) (ex. [Washington AIANNH boundaries (2020)](https://redistrictingdatahub.org/dataset/washington-aiannh-boundaries-2020/))\n",
    "- County shapefile for each state (ex. [Washington County boundaries (2020)](https://redistrictingdatahub.org/dataset/washington-county-boundaries-2020/))\n",
    "\n",
    "### Note: Please email info@redistrictingdatahub.org for any questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab405f3f-bfde-43d7-a4a1-8d7037927cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import os\n",
    "import numpy as np\n",
    "from s3_paths import *\n",
    "datafold = os.path.join(wd,'pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfc50b-8d41-401d-b03f-f265e5761cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fullname(state_ab):\n",
    "    values = ['al','ak','az','ar','ca','co','ct','de','fl','ga','hi','id','il','in','ia','ks','ky','la','me','md','ma','mi','mn','ms','mo','mt','ne','nv','nh','nj','nm','ny','nc','nd','oh','ok','or','pa','ri','sc','sd','tn','tx','ut','vt','va','wa','wv','wi','wy']\n",
    "    keys = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas','Utah','Virginia','Washington','West Virginia','Wisconsin','Wyoming']\n",
    "    dictionary = dict(zip(keys,values))\n",
    "    state_name = ''\n",
    "    for k, v in dictionary.items():\n",
    "        if v == state_ab:\n",
    "            state_name = k\n",
    "    return state_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff859986-ae62-4b92-93d2-3e350ae0f373",
   "metadata": {},
   "source": [
    "Import block level data for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7615fa-bc25-4536-a8f8-54d9beace378",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict ={}\n",
    "for i in os.listdir(datafold):\n",
    "    cols_keep= ['GEOCODE','AIANHHNS','AIHHTLI','AIANHH','AIANHHFP','AIANHHCC','AITS','AITSFP','AITSCC','AITSNS','TTRACT','TBLKGRP']\n",
    "    sa  = i.split('_')[0]\n",
    "    df= pd.read_csv(os.path.join(datafold,i))\n",
    "    df = df[cols_keep]\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "        list1=list(df[col])\n",
    "        max_len = -1\n",
    "        for ele in list1: \n",
    "            if(len(ele) > max_len): \n",
    "                max_len = len(ele)\n",
    "        df[col]=df[col].apply(lambda x: str(x).zfill(max_len))\n",
    "    df['GEOID20'] = df['GEOCODE'].apply(lambda x: str(x).zfill(15))\n",
    "    df['STATEFP20'] = df['GEOID20'].apply(lambda x: str(x)[0:2])\n",
    "    df['COUNTYFP20'] = df['GEOID20'].apply(lambda x: str(x)[2:5])\n",
    "    df['TRACTCE20'] = df['GEOID20'].apply(lambda x: str(x)[5:11])\n",
    "    df['BLOCKCE20'] = df['GEOID20'].apply(lambda x: str(x)[11:15])\n",
    "    df['AIA_GEOID'] = df['AIANHH']+df['AIHHTLI']\n",
    "    data_dict.update({sa:df})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15522f59-c526-4cb5-9640-79b334913240",
   "metadata": {},
   "source": [
    "Assign AIANHH names and IN/OUT of AIANHH and Tribal Block Group designations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba0404-6830-4916-a951-180a227e525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_copy = data_dict.copy()\n",
    "for k,v in data_dict_copy.items():\n",
    "    #print('**************',k,'*************')\n",
    "    county = gp.read_file(f'zip+{county_base+k}_cnty_2020_bound.zip')\n",
    "    county_dict = dict(zip(list(county['COUNTYFP20']),list(county['NAMELSAD20'])))\n",
    "    v['COUNTY'] = v['COUNTYFP20'].apply(lambda x: county_dict.get(str(x)))\n",
    "    try:\n",
    "        aia = gp.read_file(f'zip+{aia_base+k}_aiannh_2020_bound.zip')\n",
    "        aia_dict = dict(zip(list(aia['GEOID20']),list(aia['NAMELSAD20'])))\n",
    "        #display(aia.head())\n",
    "        v['IN_TBLKGRP'] = v['TBLKGRP'].apply(lambda x: 'YES' if x!='9' else 'NO')\n",
    "        v['IN_AIANHH'] = v['AIA_GEOID'].apply(lambda x: 'YES' if x!='99999' else 'NO')\n",
    "        v['AIA_NAME'] = v['AIA_GEOID'].apply(lambda x: aia_dict.get(x) if x in aia_dict.keys() else 'N/A')\n",
    "    except:\n",
    "        #print('***NO AIA***')\n",
    "\n",
    "        v['IN_TBLKGRP'] = 'NO'\n",
    "        v['IN_AIANHH'] = 'NO'\n",
    "        v['AIA_NAME'] = 'N/A'\n",
    "    #display(v.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae8009-0542-4345-a74b-3e85e460fdc0",
   "metadata": {},
   "source": [
    "Create state-level files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250c27a-188c-4085-b027-c9c6174005e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in data_dict_copy.items():\n",
    "    #print(k)\n",
    "    v['STATE']= assign_fullname(k)\n",
    "    \n",
    "    order = ['GEOID20','STATE', 'STATEFP20','COUNTY', 'COUNTYFP20', 'TRACTCE20', 'BLOCKCE20',\n",
    "             'IN_AIANHH','IN_TBLKGRP',\n",
    "             'AIA_NAME','AIA_GEOID','AIANHHNS',\n",
    "             'AIHHTLI', 'AIANHH', 'AIANHHFP', 'AIANHHCC',\n",
    "       'TTRACT', 'TBLKGRP' ,\n",
    "            'AITS', 'AITSFP', 'AITSCC', 'AITSNS']\n",
    "    v = v[order]\n",
    "    fold = os.path.join(wd,'STATE_BAFS')\n",
    "    if not os.path.exists(fold):\n",
    "        os.mkdir(fold)\n",
    "    path = os.path.join(fold,k+'_aia_baf.csv')\n",
    "    v.to_csv(path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89680fb5-af47-4822-8769-68b8361c871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in os.listdir(fold):\n",
    "    df = pd.read_csv(os.path.join(fold,i))\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e6a641-598c-4dd5-bfad-6c8270acc3ad",
   "metadata": {},
   "source": [
    "Concat state files into national file and assign 'NULL' to applicable blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b7bf1b-e867-47bd-8a95-656838e42408",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = pd.concat(dfs)\n",
    "nat.rename(columns = {'AIA_NAME':'AIANHH_NAME','AIA_GEOID':'AIANHH_GEOID'},inplace=True)\n",
    "nat.reset_index(inplace=True,drop=True)\n",
    "\n",
    "nat['GEOID20'] = nat['GEOID20'].apply(lambda x: str(x).zfill(15))\n",
    "nat['STATEFP20'] = nat['STATEFP20'].apply(lambda x: str(x).zfill(2))\n",
    "nat['COUNTYFP20'] = nat['COUNTYFP20'].apply(lambda x: str(x).zfill(3))\n",
    "nat['TRACTCE20'] = nat['TRACTCE20'].apply(lambda x: str(x).zfill(6))\n",
    "nat['BLOCKCE20'] = nat['BLOCKCE20'].apply(lambda x: str(x).zfill(4))\n",
    "\n",
    "nat['AIANHH_GEOID'] =nat['AIANHH_GEOID'].apply(lambda x: 'NULL' if str(x)=='99999' else x)\n",
    "nat['AIANHHNS'] =nat['AIANHHNS'].apply(lambda x: 'NULL' if str(x)=='99999999' else x)\n",
    "nat['AIHHTLI'] =nat['AIHHTLI'].apply(lambda x: 'NULL' if str(x)=='9' else x)\n",
    "nat['AIANHH'] =nat['AIANHH'].apply(lambda x: 'NULL' if str(x)=='9999' else x)\n",
    "nat['AIANHHFP'] =nat['AIANHHFP'].apply(lambda x: 'NULL' if str(x)=='99999' else x)\n",
    "nat['AIANHHCC'] =nat['AIANHHCC'].apply(lambda x: 'NULL' if str(x)=='99' else x)\n",
    "nat['TTRACT'] =nat['TTRACT'].apply(lambda x: 'NULL' if str(x)=='999999' else x)\n",
    "nat['TBLKGRP'] =nat['TBLKGRP'].apply(lambda x: 'NULL' if str(x)=='9' else x)\n",
    "nat['AITS'] =nat['AITS'].apply(lambda x: 'NULL' if str(x)=='999' else x)\n",
    "nat['AITSFP'] =nat['AITSFP'].apply(lambda x: 'NULL' if str(x)=='99999' else x)\n",
    "nat['AITSCC'] =nat['AITSCC'].apply(lambda x: 'NULL' if str(x)=='99' else x)\n",
    "nat['AITSNS'] =nat['AITSNS'].apply(lambda x: 'NULL' if str(x)=='99999999' else x)\n",
    "\n",
    "nat['AIANHH_NAME'] = nat['AIANHH_NAME'].fillna('NULL')\n",
    "\n",
    "nat.to_csv(os.path.join(fold,'national_block_assignment_aianhh.csv'),index=False)\n",
    "\n",
    "display(nat.head())\n",
    "print(len(nat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0e12b-cbcf-4614-af8b-1507a9e67e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
