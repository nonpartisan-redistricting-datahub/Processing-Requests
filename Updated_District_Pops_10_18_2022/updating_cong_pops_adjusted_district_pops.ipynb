{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c67d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae91d97",
   "metadata": {},
   "source": [
    "## Updating CD Pop and Adjusted Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06068823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/0q4w6hm92mg_zxd84dfxmq3m0000gn/T/ipykernel_59554/3065365752.py:2: DtypeWarning: Columns (3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  updated_baf_boundary = pd.read_csv(\"./raw-from-source/national_baf_boundary/national_baf_boundary.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load in the new BAF file\n",
    "updated_baf_boundary = pd.read_csv(\"./raw-from-source/national_baf_boundary/national_baf_boundary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb28acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CD ID\n",
    "updated_baf_boundary[\"CONG-ID\"] = updated_baf_boundary[\"STATE\"]+\"-\"+updated_baf_boundary[\"CONG\"].astype(str)\n",
    "\n",
    "# Groupby this ID\n",
    "cong_totals = updated_baf_boundary.groupby([\"CONG-ID\"]).sum()\n",
    "\n",
    "# Reset index, drop columns, cast pop data to integer and remove \"NO VALUE\" districts\n",
    "cong_totals.reset_index(drop = False, inplace = True)\n",
    "cong_totals.drop([\"GEOID20\"], axis = 1, inplace = True)\n",
    "cong_totals[\"P0010001\"] = cong_totals[\"P0010001\"].astype(int)\n",
    "cong_totals = cong_totals[~cong_totals[\"CONG-ID\"].str.contains(\"NO\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af24f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in old file as a check\n",
    "old_cong_file = pd.read_csv(\"/Users/peterhorton/Documents/RDH/Support/Processing-Requests/Updated_District_Pops_10_18_2022/raw-from-source/cd_pop_2022_csv/cd_pop_2022_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ffc66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CONG-ID, P0010001_x, STATE, DISTRICT, CD_ID, P0010001_y, _merge]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary to make the join to the older file work\n",
    "cong_dict = {\"2801\":\"1\",\n",
    "\"2802\":\"2\",\n",
    "\"2803\":\"3\",\n",
    "\"2804\":\"4\"}\n",
    "\n",
    "# Join the two together\n",
    "old_cong_file[\"DISTRICT\"] = old_cong_file[\"DISTRICT\"].map(cong_dict).fillna(old_cong_file[\"DISTRICT\"])\n",
    "old_cong_file[\"CONG-ID\"] = old_cong_file[\"STATE\"] + \"-\" + old_cong_file[\"DISTRICT\"].astype(str).str.upper()\n",
    "combined = pd.merge(cong_totals, old_cong_file, how = \"outer\", on = \"CONG-ID\", indicator = True)\n",
    "\n",
    "# Confirm that everything joins\n",
    "print(combined[combined[\"_merge\"]!=\"both\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96e9c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    435\n",
       "Name: Pop_Diff, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if there are any differences across the two files\n",
    "combined[\"Pop_Diff\"] = combined[\"P0010001_x\"] - combined[\"P0010001_y\"]\n",
    "combined[\"Pop_Diff\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8ed0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the columns\n",
    "cong_totals[\"STATE\"] = cong_totals[\"CONG-ID\"].apply(lambda x: x.split(\"-\")[0])\n",
    "cong_totals[\"DISTRICT\"] = cong_totals[\"CONG-ID\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "\n",
    "# Filter the columns\n",
    "cong_totals = cong_totals[[\"STATE\",\"DISTRICT\",\"CONG-ID\",\"P0010001\"]]\n",
    "\n",
    "# Final population check\n",
    "sum(cong_totals[\"P0010001\"])\n",
    "\n",
    "# Export to csv\n",
    "cong_totals.to_csv(\"./cong_totals.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6afbb0",
   "metadata": {},
   "source": [
    "## Adjusted District Populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0318e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the national BAF\n",
    "national_baf = pd.read_csv(\"./raw-from-source/national_baf_boundary/national_baf_boundary.csv\", dtype =({\"GEOID20\":str, \"STATEAB\":str, \"CONG\":str, \"SLDU\":str, \"SLDL\":str, \"FLOTERIAL\":str}))\n",
    "\n",
    "# Create columns for the various districts\n",
    "national_baf[\"UNQ_CONG_DIST_ID\"] = national_baf[\"STATE\"] + \"-\" + national_baf[\"CONG\"].astype(str)\n",
    "national_baf[\"UNQ_SLDL_DIST_ID\"] = national_baf[\"STATE\"] + \"-\" + national_baf[\"SLDL\"].astype(str)\n",
    "national_baf[\"UNQ_SLDU_DIST_ID\"] = national_baf[\"STATE\"] + \"-\" + national_baf[\"SLDU\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89556002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the GEOID column\n",
    "national_baf[\"GEOID20\"] = national_baf[\"GEOID20\"].astype(str).str.zfill(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a52853",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_data_state_subset = ['CA', 'CO', 'CT', 'DE', 'HI', 'MD', 'MT', 'NJ', 'NV',\n",
    "'NY', 'PA', 'VA', 'WA']\n",
    "\n",
    "def mod_census(block_id):\n",
    "    block_id = str(block_id)\n",
    "    \n",
    "    # PA appends a letter to the GEOID for the split blocks\n",
    "    if \"A\" in block_id or \"B\" in block_id or \"C\" in block_id:\n",
    "        \n",
    "        # Return the GEOID with out the split so the blocks can be combined\n",
    "        return block_id[:len(block_id)-1]\n",
    "    \n",
    "    # If it's not one of these special blocks, just return the GEOID\n",
    "    else:\n",
    "        return block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the state data\n",
    "adjusted_data_list = []\n",
    "\n",
    "# Iterate over the states\n",
    "for state in adjusted_data_state_subset:\n",
    "    \n",
    "    # Load and filter the data\n",
    "    adj_state = pd.read_csv(\"./raw-from-source/Adjusted_Counts/\"+state+\"_blocks.csv\")\n",
    "    adj_state = adj_state[[\"GEOID20\", \"Adj_Pop\"]]\n",
    "    \n",
    "    # Deal with PA split blocks\n",
    "    if state == \"PA\":\n",
    "        \n",
    "        # Use the above function to return the \"unsplit\" GEOID\n",
    "        adj_state[\"mod_GEOID20\"] = adj_state[\"GEOID20\"].apply(lambda x: mod_census(x))\n",
    "        \n",
    "        # Because the splits blocks are in the same districts, we can join them together to match PL geographies\n",
    "        adj_state_mod = adj_state.groupby(\"mod_GEOID20\").sum()\n",
    "        \n",
    "        # Clean the index and rename columns to match others\n",
    "        adj_state_mod.reset_index(drop = False, inplace = True)\n",
    "        adj_state_mod.rename(columns = {\"mod_GEOID20\":\"GEOID20\"}, inplace = True)\n",
    "        adj_state_mod = adj_state_mod[[\"GEOID20\", \"Adj_Pop\"]]\n",
    "        \n",
    "        # Append the PA data to the list\n",
    "        adjusted_data_list.append(adj_state_mod)\n",
    "    \n",
    "    # For other states just add the data\n",
    "    else:\n",
    "        adjusted_data_list.append(adj_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d73b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the list to the dataframe\n",
    "adj_state_data_df = pd.concat(adjusted_data_list)\n",
    "\n",
    "# Clean the columns\n",
    "adj_state_data_df[\"Adj_Pop\"] = adj_state_data_df[\"Adj_Pop\"].astype(int)\n",
    "adj_state_data_df[\"GEOID20\"] = adj_state_data_df[\"GEOID20\"].astype(str).str.zfill(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two files together\n",
    "adjusted_counts = pd.merge(national_baf, adj_state_data_df, how = \"outer\", on = \"GEOID20\", indicator = True)\n",
    "\n",
    "# Check the join\n",
    "adjusted_counts[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33542f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that there is no population for any of the unjoined blocks\n",
    "sum(adjusted_counts[adjusted_counts[\"_merge\"]==\"right_only\"][\"Adj_Pop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to join blocks or blocks in RI (need that to get the district data for the state)\n",
    "joined = adjusted_counts[(adjusted_counts[\"_merge\"]==\"both\") | (adjusted_counts[\"STATE\"]==\"RI\")]\n",
    "\n",
    "# Clean the columns\n",
    "joined[\"Adj_Pop\"] = joined[\"Adj_Pop\"].fillna(0)\n",
    "joined[\"Adj_Pop\"] = joined[\"Adj_Pop\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6056db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(joined[\"STATE\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[\"STATE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of states that use adjusted data for congressional redistricting\n",
    "uses_cong = joined[joined[\"STATE\"].isin([\"CA\", \"MD\", \"NJ\", \"NV\", \"RI\", \"VA\", \"WA\"])]\n",
    "\n",
    "# Aggregate to the appropriate district levels\n",
    "joined_cong = uses_cong.groupby(\"UNQ_CONG_DIST_ID\").sum()\n",
    "joined_sldl = joined.groupby(\"UNQ_SLDL_DIST_ID\").sum()\n",
    "joined_sldu = joined.groupby(\"UNQ_SLDU_DIST_ID\").sum()\n",
    "\n",
    "# Clean the aggregations\n",
    "joined_cong.reset_index(inplace = True, drop = False)\n",
    "joined_sldl.reset_index(inplace = True, drop = False)\n",
    "joined_sldu.reset_index(inplace = True, drop = False)\n",
    "\n",
    "joined_cong.drop([\"P0010001\"], axis = 1, inplace = True)\n",
    "joined_sldl.drop([\"P0010001\"], axis = 1, inplace = True)\n",
    "joined_sldu.drop([\"P0010001\"], axis = 1, inplace = True)\n",
    "\n",
    "joined_cong.columns = [\"ID\", \"Adj_Pop\"]\n",
    "joined_sldl.columns = [\"ID\", \"Adj_Pop\"]\n",
    "joined_sldu.columns = [\"ID\", \"Adj_Pop\"]\n",
    "\n",
    "joined_cong[\"Level\"] = \"CONG\"\n",
    "joined_sldl[\"Level\"] = \"SLDL\"\n",
    "joined_sldu[\"Level\"] = \"SLDU\"\n",
    "\n",
    "# Join them back into one file\n",
    "combined_files = pd.concat([joined_cong, joined_sldl, joined_sldu])\n",
    "\n",
    "# Get the state abbreviation\n",
    "combined_files[\"State\"] = combined_files[\"ID\"].apply(lambda x: x[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in a leading zero for the RI data so it will join\n",
    "#ri_update_dict = {\"RI-1\":\"RI-01\",\"RI-2\":\"RI-02\"}\n",
    "\n",
    "# Apply this update\n",
    "#combined_files[\"ID\"] = combined_files[\"ID\"].map(ri_update_dict).fillna(combined_files[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ab28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ID of the level and the ID so we can join to RI\n",
    "combined_files[\"unique_id\"] = combined_files[\"Level\"]+\"-\"+combined_files[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the RI data\n",
    "ri_data = pd.read_csv(\"./raw-from-source/ri_sizes.csv\",dtype={\"Number\":str, \"Adj_Pop\":int, \"Level\":str})\n",
    "\n",
    "# Create a unique ID to join with the pop. file\n",
    "ri_data[\"unique_id\"] = ri_data[\"Level\"]+\"-RI-\"+ri_data[\"Number\"].astype(str)\n",
    "\n",
    "# Make the population an integer\n",
    "ri_data[\"Adj_Pop\"] = ri_data[\"Adj_Pop\"].astype(int)\n",
    "\n",
    "# Create a dictionary mapping from district ID to population in RI\n",
    "ri_data_dict = dict(zip(ri_data[\"unique_id\"], ri_data[\"Adj_Pop\"]))\n",
    "\n",
    "# Apply the above dictionary to the RI districts in the combined file\n",
    "combined_files[\"Adj_Pop\"] = combined_files[\"unique_id\"].map(ri_data_dict).fillna(combined_files[\"Adj_Pop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_files[\"state-level\"] = combined_files[\"State\"]+\"-\"+combined_files[\"Level\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_files[\"Adj_Pop\"] = combined_files[\"Adj_Pop\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_files[combined_files[\"Adj_Pop\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"No Data\" districts (these were unassigned blocks we kept in the BAF)\n",
    "combined_files = combined_files[~combined_files[\"ID\"].str.contains(\"NO\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e57920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "combined_files.drop([\"unique_id\",\"state-level\"], axis = 1, inplace = True)\n",
    "combined_files[\"ID\"] = combined_files[\"ID\"].apply(lambda x: x.split(\"-\")[1])\n",
    "\n",
    "combined_files_join = combined_files.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac737ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Cleaning\n",
    "combined_files.columns = [\"DISTRICT\", \"ADJ_POP\", \"LEVEL\", \"STATE\"]\n",
    "combined_files = combined_files[[\"STATE\", \"DISTRICT\", \"LEVEL\", \"ADJ_POP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_files = combined_files.sort_values([\"STATE\", \"LEVEL\", \"DISTRICT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c48a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_files.to_csv(\"./adjusted_districts_pop.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb038cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check against old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_adjusted_pops = pd.read_csv(\"./raw-from-source/national_districts_adjusted_pop/adjusted_districts_pop.csv\")\n",
    "\n",
    "combined_files_join[\"DIST-ID\"] = combined_files_join[\"State\"] +\"-\"+combined_files_join[\"Level\"] +\"-\"+  combined_files_join[\"ID\"].astype(str).str.zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_adjusted_pops[\"DIST-ID\"] = old_adjusted_pops[\"State\"]+ \"-\" + old_adjusted_pops[\"Level\"] + \"-\" + old_adjusted_pops[\"ID\"].astype(str).astype(str).str.zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_adjusted = pd.merge(combined_files_join, old_adjusted_pops, how = \"outer\", on = \"DIST-ID\", indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce223bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_adjusted[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_adjusted[\"Difference\"] = joined_adjusted[\"Adj_Pop_x\"] - joined_adjusted[\"Adj_Pop_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_adjusted[joined_adjusted[\"Difference\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(joined_adjusted[joined_adjusted[\"Difference\"]!=0][\"Difference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ec738",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_adjusted[joined_adjusted[\"Difference\"]!=0][[\"DIST-ID\",\"Difference\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
